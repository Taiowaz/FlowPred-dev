{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# 魔术指令，自动加载模块\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/beihang/xihu/HZTourism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/ogn/mobile_signaling_tourists_num.csv\")\n",
    "# 筛选spot_id=14100的数据\n",
    "df = df[df[\"spot_id\"] == 14100]\n",
    "df[\"kpi_time\"] = pd.to_datetime(df[\"kpi_time\"])\n",
    "# 按照kpi_time升序排序\n",
    "df = df.sort_values(\"kpi_time\")\n",
    "# 数据按时间去重\n",
    "df = df.drop_duplicates(\"kpi_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      id  spot_id  kpi_id            kpi_time  kpi_value\n",
       " 0     63    14100    1001 2021-09-01 00:00:00       9752\n",
       " 58   121    14100    1001 2021-09-07 15:00:00      32346\n",
       " 116  179    14100    1001 2021-09-07 15:05:00      32346\n",
       " 174  237    14100    1001 2021-09-07 15:10:00      30302\n",
       " 232  295    14100    1001 2021-09-07 15:15:00      30302,\n",
       "                 id  spot_id  kpi_id            kpi_time  kpi_value\n",
       " 19930506  39858527    14100    1001 2025-04-11 14:10:00      55238\n",
       " 19930562  39858639    14100    1001 2025-04-11 14:15:00      55715\n",
       " 19930618  39858751    14100    1001 2025-04-11 14:20:00      55715\n",
       " 19930674  39858863    14100    1001 2025-04-11 14:25:00      55207\n",
       " 19930730  39858975    14100    1001 2025-04-11 14:30:00      55207)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data.utils_data import (\n",
    "    filter_days_with_less_consecutive_missing,\n",
    "    fill_missing_value_singlespot_day,\n",
    ")\n",
    "\n",
    "# 分别筛选出2024年的数据以及2025年的数据\n",
    "df_2024 = df[df[\"kpi_time\"].dt.year == 2024]\n",
    "df_2025 = df[df[\"kpi_time\"].dt.year == 2025]\n",
    "# 数据去重\n",
    "df_2024 = df_2024.drop_duplicates(subset=[\"kpi_time\"])\n",
    "df_2025 = df_2025.drop_duplicates(subset=[\"kpi_time\"])\n",
    "# 筛选连续数据缺值不多于5条的数据\n",
    "df_2024 = filter_days_with_less_consecutive_missing(df=df_2024, freq=\"5min\", k=5)\n",
    "df_2025 = filter_days_with_less_consecutive_missing(df=df_2025, freq=\"5min\", k=5)\n",
    "# 填充单值\n",
    "df_2024 = fill_missing_value_singlespot_day(df_2024)\n",
    "df_2025 = fill_missing_value_singlespot_day(df_2025)\n",
    "# 去除id列与kpi_id列\n",
    "df_2024 = df_2024.drop(columns=[\"id\", \"kpi_id\"])\n",
    "df_2025 = df_2025.drop(columns=[\"id\", \"kpi_id\"])\n",
    "df_2024.to_csv(\"data/0411/ogn/24/df_2024.csv\", index=False)\n",
    "df_2025.to_csv(\"data/0411/ogn/25/df_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读入，首先按照时间间隔分组，`前后相差一天的分一次组\n",
    "# 然后按照模式分组，同一模式的分一次组\n",
    "df_2024 = pd.read_csv(\"data/0411/ogn/24/df_2024.csv\")\n",
    "df_2025 = pd.read_csv(\"data/0411/ogn/25/df_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# 获取分组的编码标注数据,返回两个dataframe列表\n",
    "def get_group_annotation(df, his_len=288, pred_len=24):\n",
    "    # 转换kpi_time为datetime类型\n",
    "    df[\"kpi_time\"] = pd.to_datetime(df[\"kpi_time\"])\n",
    "    # 对kpi_time进行升序排序\n",
    "    df = df.sort_values(by=\"kpi_time\")\n",
    "    df[\"mode\"] = df[\"kpi_time\"].dt.weekday.apply(lambda x: 1 if x < 5 else 0)\n",
    "    # 按天进行分组\n",
    "    daily_groups = df.groupby(df[\"kpi_time\"].dt.date)\n",
    "    # 遍历每个分组，如果前后两个分组的时间差为一天，则将它们合并，否则新键一个分组\n",
    "    all_groups = []\n",
    "    # 先添加第一个分组\n",
    "\n",
    "    prev_group_name, first_group = next(iter(daily_groups))\n",
    "    all_groups.append(first_group)\n",
    "\n",
    "    # 从第二个分组开始遍历\n",
    "    for i, (group_name, group) in enumerate(daily_groups):\n",
    "        if i > 0:\n",
    "            if (group_name - prev_group_name).days == 1:\n",
    "                all_groups[-1] = pd.concat([all_groups[-1], group])\n",
    "            else:\n",
    "                all_groups.append(group)\n",
    "            prev_group_name = group_name\n",
    "    # 遍历每个分组，从每个分组的第his_len个元素开始\n",
    "    groups_mode_0 = []\n",
    "    groups_mode_1 = []\n",
    "    for group in all_groups:\n",
    "        if len(group) < his_len + pred_len:\n",
    "            continue\n",
    "        # 第一组样例\n",
    "        # 获取mode第his_len到his_len+pred_len个元素\n",
    "        data_temp = group[: his_len + pred_len]\n",
    "        modes = group[\"mode\"][his_len : his_len + pred_len]\n",
    "        # 统计一下，看看mode=0与mode=1的个数\n",
    "        num_mode_0 = np.sum(modes == 0)\n",
    "        num_mode_1 = pred_len - num_mode_0\n",
    "        if num_mode_1 >= num_mode_0:\n",
    "            mode = 1\n",
    "        else:\n",
    "            mode = 0\n",
    "        mode_pre = mode\n",
    "        # 遍历每个分组，从每个分组的第his_len个元素开始\n",
    "        for i in range(his_len, len(group) - pred_len + 1):\n",
    "            # 获取第i个元素\n",
    "            data_i = group.iloc[i]\n",
    "            # 获取第i+pred_len个元素\n",
    "            data_j = group.iloc[i + pred_len - 1]\n",
    "            if data_i[\"mode\"] != data_j[\"mode\"]:\n",
    "                if data_i[\"mode\"] == 1:\n",
    "                    num_mode_1 -= 1\n",
    "                    num_mode_0 += 1\n",
    "                else:\n",
    "                    num_mode_0 -= 1\n",
    "                    num_mode_1 += 1\n",
    "            # 获取训练集组合\n",
    "            if mode == mode_pre:\n",
    "                data_temp = pd.concat([data_temp, data_j.to_frame().T])\n",
    "                if i == len(group) - pred_len:\n",
    "                    if mode_pre == 0:\n",
    "                        groups_mode_0.append(data_temp)\n",
    "                    else:\n",
    "                        groups_mode_1.append(data_temp)\n",
    "            else:\n",
    "                if mode_pre == 0:\n",
    "                    groups_mode_0.append(data_temp)\n",
    "                else:\n",
    "                    groups_mode_1.append(data_temp)\n",
    "                # 前his_len到当前元素\n",
    "                data_temp = group[i - his_len : i]\n",
    "            mode_pre = mode\n",
    "    return groups_mode_0, groups_mode_1\n",
    "\n",
    "\n",
    "# 保存每种模式的数据\n",
    "def save_mode_data(groups_mode, mode, his_len, data_basepath=\"data/0411/ogn/24\"):\n",
    "    data_basepath = f\"{data_basepath}/{str(his_len)}/mode_{mode}\"\n",
    "    if not os.path.exists(data_basepath):\n",
    "        os.makedirs(data_basepath)\n",
    "    for i, df_temp in enumerate(groups_mode):\n",
    "        # 按kpi_time去重\n",
    "        df_temp = df_temp.drop_duplicates(subset=[\"kpi_time\"])\n",
    "        df_temp.to_csv(f\"{data_basepath}/{str(i)}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, data_basepath in zip(\n",
    "    [df_2024, df_2025], [\"data/0411/ogn/24\", \"data/0411/ogn/25\"]\n",
    "):\n",
    "    for his_len in [288, 2016]:\n",
    "        groups_mode_0, groups_mode_1 = get_group_annotation(his_len=his_len, df=df)\n",
    "        save_mode_data(\n",
    "            groups_mode=groups_mode_0,\n",
    "            mode=0,\n",
    "            his_len=his_len,\n",
    "            data_basepath=data_basepath,\n",
    "        )\n",
    "        save_mode_data(\n",
    "            groups_mode=groups_mode_1,\n",
    "            mode=1,\n",
    "            his_len=his_len,\n",
    "            data_basepath=data_basepath,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照数据连续性进行分组\n",
    "def get_continuous_group(\n",
    "    df, save_dir=\"data/0411/ogn/24/mode_no\", his_len=288, pred_len=24\n",
    "):\n",
    "    # 转换kpi_time为datetime类型\n",
    "    df[\"kpi_time\"] = pd.to_datetime(df[\"kpi_time\"])\n",
    "    # 对kpi_time进行升序排序\n",
    "    df = df.sort_values(by=\"kpi_time\")\n",
    "    daily_groups = df.groupby(df[\"kpi_time\"].dt.date)\n",
    "    all_groups = []\n",
    "    prev_group_name, first_group = next(iter(daily_groups))\n",
    "    all_groups.append(first_group)\n",
    "\n",
    "    # 从第二个分组开始遍历\n",
    "    for i, (group_name, group) in enumerate(daily_groups):\n",
    "        if i > 0:\n",
    "            if (group_name - prev_group_name).days == 1:\n",
    "                all_groups[-1] = pd.concat([all_groups[-1], group])\n",
    "            else:\n",
    "                all_groups.append(group)\n",
    "            prev_group_name = group_name\n",
    "    for i, group in enumerate(all_groups):\n",
    "        if len(group) >= his_len + pred_len:\n",
    "            group.to_csv(f\"{save_dir}/{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024 = pd.read_csv(\"data/0411/ogn/24/df_2024.csv\")\n",
    "get_continuous_group(df=df_2024, save_dir=\"data/0411/ogn/24/mode_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2025 = pd.read_csv(\"data/0411/ogn/25/df_2025.csv\")\n",
    "get_continuous_group(df=df_2025, save_dir=\"data/0411/ogn/25/mode_no\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hztourism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
